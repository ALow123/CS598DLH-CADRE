{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS598 DLH Project: SADRE & CADRE\n",
    "Reproducing the work of \"Predicting Drug Sensitivity of Cancer Cell Lines via Collaborative Filtering with Contextual Attention\" by Yifeng Tao, Shuangxia Ren, Michael Q. Ding, Russell Schwartz, and Xinghua Lu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mounting the Repository\n",
    "Run the following cell to mount the repository locaed in your Google Drive into Google Collab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29015,
     "status": "ok",
     "timestamp": 1744174100915,
     "user": {
      "displayName": "Aaron Low",
      "userId": "08376110119987284732"
     },
     "user_tz": 420
    },
    "id": "0Rnt6z1pbimQ",
    "outputId": "8274c7ca-dbb6-477f-d65b-84769a64d843"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing the Python Version used and Importing the Necessary Packages\n",
    "A random seed is set to make tesing more reliable across different experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.metrics import auc, roc_curve, precision_recall_curve\n",
    "random.seed(598)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description and Analysis\n",
    "Use of pandas to describe and analyze the provided csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/content/drive/MyDrive/CS598_DL4H_Project/CADRE-master/data/input/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdsc_df = pd.read_csv(dataset_path+\"gdsc.csv\")\n",
    "# Find the number of cosmic ids and drug ids\n",
    "num_cosmic_ids, num_drugs = gdsc_df.shape\n",
    "# Skip the first column containing the cosmic ids\n",
    "gdsc_df_summed = gdsc_df.iloc[:, 1:].sum(axis=1, skipna=True)\n",
    "min_gene_response = gdsc_df_summed.min()\n",
    "max_gene_response = gdsc_df_summed.max()\n",
    "avg_gene_response = gdsc_df_summed.mean()\n",
    "# Create a table to display stats about the gdsc.csv file\n",
    "stats = {'num_cosmic_ids':num_cosmic_ids, 'num_drugs':num_drugs, 'min_gene_response':min_gene_response, 'max_gene_response':max_gene_response, 'avg_gene_response':avg_gene_response}\n",
    "gdsc_stats_df = pd.DataFrame.from_dict(stats, orient='index')\n",
    "print(\"Table 1: gdsc.csv Description\")\n",
    "gdsc_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_gdsc_df = pd.read_csv(dataset_path+\"exp_gdsc.csv\")\n",
    "# Find the number of cosmic ids and gene symbols\n",
    "num_cosmic_ids, num_gene_symbols = exp_gdsc_df.shape\n",
    "# Skip the first column containing the cosmic ids\n",
    "exp_gdsc_df_summed = exp_gdsc_df.iloc[:, 1:].sum(axis=1, skipna=True)\n",
    "min_gene_expression = exp_gdsc_df_summed.min()\n",
    "max_gene_expression = exp_gdsc_df_summed.max()\n",
    "avg_gene_expression = exp_gdsc_df_summed.mean()\n",
    "# Create a table to display stats about the exp_gdsc.csv file\n",
    "stats = {'num_cosmic_ids':num_cosmic_ids, 'num_gene_symbols':num_gene_symbols, 'min_gene_expression':min_gene_expression, 'max_gene_expression':max_gene_expression, 'avg_gene_expression':avg_gene_expression}\n",
    "exp_gdsc_stats_df = pd.DataFrame.from_dict(stats, orient='index')\n",
    "print(\"Table 2: exp_gdsc.csv Description\")\n",
    "exp_gdsc_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_info_gdsc_df = pd.read_csv(dataset_path+\"drug_info_gdsc.csv\")\n",
    "# Find the number of drug ids, unique targets, and unique target pathways\n",
    "num_drug_ids = len(drug_info_gdsc_df['drug_id'].unique())\n",
    "unique_targets = len(drug_info_gdsc_df['Targets'].unique())\n",
    "unique_target_pathways = len(drug_info_gdsc_df['Target pathway'].unique())\n",
    "# For each drug find the min, max, and avg sample size\n",
    "drug_info_gdsc_df_sample_size = drug_info_gdsc_df['Sample Size']\n",
    "min_sample_size = drug_info_gdsc_df_sample_size.min()\n",
    "max_sample_size = drug_info_gdsc_df_sample_size.max()\n",
    "avg_sample_size = drug_info_gdsc_df_sample_size.mean()\n",
    "# Create a table to display stats about the exp_gdsc.csv file\n",
    "stats = {'num_drug_ids':num_drug_ids, 'unique_targets':unique_targets, 'unique_target_pathways':unique_target_pathways, 'min_sample_size':min_sample_size, 'max_sample_size':max_sample_size, 'avg_sample_size':avg_sample_size}\n",
    "drug_info_gdsc_stats_df = pd.DataFrame.from_dict(stats, orient='index')\n",
    "print(\"Table 3: drug_info_gdsc.csv Description\")\n",
    "drug_info_gdsc_stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing the training and evaluation of the SADRE & CADRE models\n",
    "Run the following cell to execute the training and evaluation of the models. \n",
    "\n",
    "**Note**: Be sure to change the runtime to \"T4 GPU\" in order to have the necessary resources to run the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 76249,
     "status": "ok",
     "timestamp": 1744076572458,
     "user": {
      "displayName": "Kevin Zhou",
      "userId": "01261011481288091605"
     },
     "user_tz": 420
    },
    "id": "sVK5_eCJbauU",
    "outputId": "abb0ab02-c097-4192-d237-d845e0287ed1"
   },
   "outputs": [],
   "source": [
    "# Takes ~25 min to finish running, CF/SADRE is fast, CADRE training is slower\n",
    "!python /content/drive/MyDrive/CS598/CADRE-master/run_cf.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Analysis and Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CF = [['Collaborative Filtering', 0.4, 0.1, 41.7, 52.8, 37.0, 52.9],\n",
    "      ['Collaborative Filtering', 0.4, 0.3, 42.5, 54.8, 37.2, 54.5],\n",
    "      ['Collaborative Filtering', 0.4, 0.5, 44.2, 57.1, 39.2, 57.4],\n",
    "      ['Collaborative Filtering', 0.6, 0.1, 40.3, 50.7, 34.7, 50.9],\n",
    "      ['Collaborative Filtering', 0.6, 0.3, 42.1, 54.8, 36.6, 54.5],\n",
    "      ['Collaborative Filtering', 0.6, 0.5, 44.3, 56.6, 41.1, 57.6],\n",
    "      ['Collaborative Filtering', 0.8, 0.1, 40.3, 51.3, 34.6, 51.2],\n",
    "      ['Collaborative Filtering', 0.8, 0.3, 42.6, 52.8, 36.3, 53.5],\n",
    "      ['Collaborative Filtering', 0.8, 0.5, 41.3, 53.6, 36.7, 53.6]]\n",
    "SADRE = [['SADRE', 0.4, 0.1, 39.9, 50.0, 34.5, 49.8],\n",
    "         ['SADRE', 0.4, 0.3, 42.1, 55.5, 38.8, 55.3],\n",
    "         ['SADRE', 0.4, 0.5, 44.1, 57.1, 39.4, 57.7],\n",
    "         ['SADRE', 0.6, 0.1, 41.1, 52.4, 35.0, 52.4],\n",
    "         ['SADRE', 0.6, 0.3, 42.1, 53.5, 35.9, 53.5],\n",
    "         ['SADRE', 0.6, 0.5, 43.0, 56.1, 37.9, 56.1],\n",
    "         ['SADRE', 0.8, 0.1, 40.2, 50.3, 33.7, 50.0],\n",
    "         ['SADRE', 0.8, 0.3, 40.8, 51.4, 34.6, 51.1],\n",
    "         ['SADRE', 0.8, 0.5, 42.6, 55.3, 38.0, 55.2]]\n",
    "CADRE_no_pretrain = [['CADRE w/o pretrain', 0.4, 0.1, 53.6, 69.2, 56.1, 70.9],\n",
    "                     ['CADRE w/o pretrain', 0.4, 0.3, 54.2, 70.4, 56.8, 72.4],\n",
    "                     ['CADRE w/o pretrain', 0.4, 0.5, 55.3, 71.8, 59.1, 73.8],\n",
    "                     ['CADRE w/o pretrain', 0.6, 0.1, 52.1, 67.5, 53.2, 69.1],\n",
    "                     ['CADRE w/o pretrain', 0.6, 0.3, 53.2, 68.9, 55.3, 70.7],\n",
    "                     ['CADRE w/o pretrain', 0.6, 0.5, 53.7, 69.6, 56.9, 71.5],\n",
    "                     ['CADRE w/o pretrain', 0.8, 0.1, 48.2, 62.7, 47.6, 63.9],\n",
    "                     ['CADRE w/o pretrain', 0.8, 0.3, 49.7, 64.5, 49.0, 65.6],\n",
    "                     ['CADRE w/o pretrain', 0.8, 0.5, 50.4, 65.2, 50.4, 66.8]]\n",
    "CADRE_with_pretrain = [['CADRE with pretrain', 0.4, 0.1, 47.8, 62.4, 46.6, 63.5],\n",
    "                       ['CADRE with pretrain', 0.4, 0.3, 52.9, 68.7, 52.8, 69.8],\n",
    "                       ['CADRE with pretrain', 0.4, 0.5, 53.9, 69.9, 55.2, 71.5],\n",
    "                       ['CADRE with pretrain', 0.6, 0.1, 45.3, 59.0, 43.8, 59.6],\n",
    "                       ['CADRE with pretrain', 0.6, 0.3, 48.9, 63.6, 45.7, 64.6],\n",
    "                       ['CADRE with pretrain', 0.6, 0.5, 50.5, 66.1, 46.9, 67.2],\n",
    "                       ['CADRE with pretrain', 0.8, 0.1, 42.2, 55.0, 35.6, 54.0],\n",
    "                       ['CADRE with pretrain', 0.8, 0.3, 10.2, 65.4, 37.6, 51.1],\n",
    "                       ['CADRE with pretrain', 0.8, 0.5, 0.5, 65.9, 27.5, 50.2]]\n",
    "\n",
    "results = pd.DataFrame(CF + SADRE + CADRE_no_pretrain + CADRE_with_pretrain, columns=['model', 'dropout_rate', 'learning_rate', 'f1 score', 'accuracy', 'AUPR', 'AUROC'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_by_test_f1 = results.loc[\n",
    "    results.groupby(['dropout_rate', 'learning_rate'])['f1 score'].idxmax()\n",
    "].sort_values(by='f1 score', ascending=False)\n",
    "best_by_test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_by_test_acc = results.loc[\n",
    "    results.groupby(['dropout_rate', 'learning_rate'])['accuracy'].idxmax()\n",
    "].sort_values(by='accuracy', ascending=False)\n",
    "best_by_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[results['dropout_rate'] == 0.4].groupby('model').mean().reset_index().drop('learning_rate', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[results['dropout_rate'] == 0.6].groupby('model').mean().reset_index().drop('learning_rate', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[results['dropout_rate'] == 0.8].groupby('model').mean().reset_index().drop('learning_rate', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_CF = [['Collaborative Filtering', 43.1, 57.5, 40.4, 57.3]]\n",
    "ablation_SADRE = [['SADRE', 45.3, 59.4, 42.3, 59.8]]\n",
    "ablation_CADRE_no_pretrain = [['CADRE w/o pretrain', 53.9, 70.3, 57.1, 72.0]]\n",
    "ablation_CADRE_with_pretrain = [['CADRE with pretrain', 30.4, 62.4, 38.6, 54.0]]\n",
    "\n",
    "ablation_results = pd.DataFrame(ablation_CF + ablation_SADRE + ablation_CADRE_no_pretrain + ablation_CADRE_with_pretrain, columns=['model', 'f1 score', 'accuracy', 'AUPR', 'AUROC'])\n",
    "ablation_results"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
